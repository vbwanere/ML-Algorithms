{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Physics Informed Neural Network"]},{"cell_type":"markdown","metadata":{"id":"0eMvcaTbDnfw"},"source":["Simulation of complex physical systems described by nonlinear partial differential equations (PDEs) is central to engineering and physical science. We'll now train a neural network to solve a PDE given the boundary conditions. Till now, we have trained an MLP through data and penalize the network until it learns what we desire. However, in the case of PDEs, we can use knowledge of the known PDE to guide the training. Using the core idea of [PINNs](https://www.sciencedirect.com/science/article/pii/S0021999118307125), train a network to solve the Poisson equation \n","$$u_{xx} + u_{yy} = -\\sin (\\pi x) \\sin(\\pi y)$$\n","with the following BCs:\n","$$u(0, y) = u(1, y) = u(x, 1) = u(x, 1) = 0$$\n","\n","Utilize 10000 collocation points in the domain to enforce the PDE and 100 data-points on each boundary to enforce boundary condition. Compare your solution against the analytic solution and report error in the relative $\\mathbb{L}_{2}$ norm.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"10uBljWtDnfw","vscode":{"languageId":"plaintext"}},"outputs":[],"source":["import jax.numpy as np\n","import numpy as onp\n","from jax import random, jit, vmap, grad, device_put\n","from jax.example_libraries import optimizers\n","\n","import itertools\n","from functools import partial\n","from tqdm import trange\n","import matplotlib.pyplot as plt\n","\n","import jax"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yGCmz47AvzFt"},"outputs":[],"source":["def MLP(layers, activation=np.tanh):\n","  def init(rng_key):\n","      def init_layer(key, d_in, d_out):\n","          k1, k2 = random.split(key)\n","          glorot_stddev = 1. / np.sqrt((d_in + d_out) / 2.)\n","          W = glorot_stddev * random.normal(k1, (d_in, d_out))\n","          b = np.zeros(d_out)\n","          return W, b\n","      key, *keys = random.split(rng_key, len(layers))\n","      params = list(map(init_layer, keys, layers[:-1], layers[1:]))\n","      return params\n","  def apply(params, inputs):\n","      for W, b in params[:-1]:\n","          outputs = np.dot(inputs, W) + b\n","          inputs = activation(outputs)\n","      W, b = params[-1]\n","      outputs = np.dot(inputs, W) + b\n","      return outputs\n","  return init, apply"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WBYnIm7p0TRQ"},"outputs":[],"source":["@optimizers.optimizer\n","def adam(step_size, b1=0.9, b2=0.999, eps=1e-8):\n","    step_size = optimizers.make_schedule(step_size)\n","    def init(x0):\n","        m0 = np.zeros_like(x0)\n","        v0 = np.zeros_like(x0)\n","        return x0, m0, v0\n","    def update(i, g, state):\n","        x, m, v = state\n","        m = (1 - b1) * g + b1 * m  # First  moment estimate.\n","        v = (1 - b2) * np.square(g) + b2 * v  # Second moment estimate.\n","        mhat = m / (1 - np.asarray(b1, m.dtype) ** (i + 1))  # Bias correction.\n","        vhat = v / (1 - np.asarray(b2, m.dtype) ** (i + 1))\n","        x = x - step_size(i) * mhat / (np.sqrt(vhat) + eps)\n","        return x, m, v\n","    def get_params(state):\n","        x, _, _ = state\n","        return x\n","    return init, update, get_params"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9BZS4AVI0__i"},"outputs":[],"source":["@jax.jit\n","def step(i, opt_state, x_b, y_b, x_c, y_c):\n","    params = get_params(opt_state)\n","    gradients = grad(loss)(params, x_b, y_b, x_c, y_c)\n","    return opt_update(i, gradients, opt_state)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"igOl306R1nDB"},"outputs":[],"source":["# Data points:\n","\n","# u(0, y) = 0\n","x_bl = np.zeros(100)\n","y_bl = np.linspace(0, 1, 100)\n","\n","# u(1, y) = 0\n","x_br = np.ones(100)\n","y_br = np.linspace(0, 1, 100)\n","\n","# u(x, 0) = 0\n","x_bb = np.linspace(0, 1, 100)\n","y_bb = np.zeros(100)\n","\n","# u(x, 1) = 0\n","x_bt = np.linspace(0, 1, 100)\n","y_bt = np.ones(100)\n","\n","\n","x_b = np.concatenate((x_bb, x_br, x_bt, x_bl)) # concatenate in counter clockwise direction\n","y_b = np.concatenate((y_bb, y_br, y_bt, y_bl)) # concatenate in counter clockwise direction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ky3josjV8IRy"},"outputs":[],"source":["# collocation points:\n","x_c = np.linspace(0, 1, 100)\n","y_c = np.linspace(0, 1, 100)\n","# create individual x and y meshgrid\n","x_c, y_c = np.meshgrid(x_c, y_c)\n","\n","# flatten\n","x_c, y_c = x_c.flatten(), y_c.flatten()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jkmlRuNEKthT"},"outputs":[],"source":["rng_model = random.PRNGKey(0)\n","layers = [2, 16, 16, 1]\n","init, apply = MLP(layers)\n","params = init(rng_model) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DJ08Jm4FK2Rs"},"outputs":[],"source":["# Boundary condition function:\n","def u(params, x_b, y_b):\n","  u = apply(params, np.array([x_b, y_b]))\n","  return u[0]\n","\n","# PINN: \n","def PINN(params, x_c, y_c):\n","  \n","  u = u(params, x_c, y_c)\n","  u_xx = jax.grad(jax.grad(u, 1), 1)(params, x_c, y_c) \n","  u_yy = jax.grad(jax.grad(u, 2), 2)(params, x_c, y_c)\n","\n","  # loss:\n","  L_U = u_xx + u_yy + np.sin(np.pi*x_c) * np.sin(np.pi*y_c)\n","  return L_U"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9hpTnUe4RFlO"},"outputs":[],"source":["def loss_u(params, x_bc, y_bc):\n","    return ((jax.vmap(u, (None, 0, 0))(params, x_b, y_b))**2).mean()\n","\n","def loss_f(params, x_c, y_c):\n","    return ((jax.vmap(PINN, (None, 0, 0))(params, x_c, y_c))**2).mean()\n","\n","@jax.jit\n","def loss(params, x_b, y_b, x_c, y_c):\n","    return loss_u(params, x_b, y_b) + loss_f(params, x_c, y_c)\n","\n","# compute gradient\n","grad_loss = jax.grad(loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YdRoJemERvCx"},"outputs":[],"source":["# Optimizer initialization and update functions\n","lr = optimizers.exponential_decay(1e-3, decay_steps=100, decay_rate=0.99)\n","opt_init, opt_update, get_params = adam(lr)\n","opt_state = opt_init(params)\n","\n","loss_log = []\n","\n","# initial \n","loss_log.append(loss(params, x_b, y_b, x_c, y_c))\n","\n","# 100000 iter\n","pbar = trange(100000)\n","for it in pbar:\n","    opt_state = step(it, opt_state, x_b, y_b, x_c, y_c)\n","    if(it % 50 == 0):\n","        params = get_params(opt_state)\n","        loss_log.append(loss(params, x_b, y_b, x_c, y_c))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G1gvYLBzSXgH"},"outputs":[],"source":["plt.figure(dpi = 300)\n","plt.plot(loss_log)\n","plt.xlabel('Epoch')\n","plt.ylabel('Log Loss')\n","plt.yscale(\"log\")\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"juBLsPhOSgZD"},"outputs":[],"source":["# analytical solution\n","dydx = (np.sin(np.pi*x_c)*np.sin(np.pi*y_c)) /(2*np.pi**2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gd1lXnv4SrIQ"},"outputs":[],"source":["# our solution\n","PINN = jax.vmap(u, (None, 0, 0))(params, x_c, y_c)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XXb4bjXyS0hK"},"outputs":[],"source":["der = dydx.reshape(100, 100)\n","PINN = PINN.reshape(100,100)\n","x = x_c.reshape(100, 100)\n","y = y_c.reshape(100, 100)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
